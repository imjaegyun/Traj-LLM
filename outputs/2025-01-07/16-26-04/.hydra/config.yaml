tasks:
  train:
    lr: 0.001
    epochs: 10
    gpus: 1
    batch_size: 16
modules:
  data:
    nuscenes_path: /home/user/data/Nuscenes
    batch_size: 16
  sparse_encoder:
    input_dim: 128
    hidden_dim: 256
    output_dim: 128
  high_level_model:
    llm_model_name: meta-llama/Llama-3.2-3B
    input_dim: 128
    hidden_dim: 256
    output_dim: 128
  lane_probability:
    agent_dim: 128
    lane_dim: 128
    hidden_dim: 256
    num_lanes: 6
  laplace_decoder:
    input_dim: 128
    output_dim: 2
  wandb:
    project: Traj-LLM
    entity: your_wandb_entity
    mode: online
task: train
