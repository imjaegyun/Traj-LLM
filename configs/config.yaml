defaults:
  - tasks/train  # 기본 작업
  #- tasks/test   # 테스트 작업 추가
  - modules/data_loader
  - modules/model
  - modules/wandb

train:
  lr: 0.001
  epochs: 100
  weight_decay: 0.01
  batch_size: 16
  gpus: 1
  gradient_clip_val: 0.5  # Gradient clipping value
  lr_step: 10  # 학습률 감소 주기 (에포크 기준)
  lr_gamma: 0.1  # 학습률 감소 비율

test:
  batch_size: 16
  gpus: 1
  data_root: /home/user/data/Nuscenes
  checkpoint: /home/user/Traj-LLM/imjaegyun/Traj-LLM/outputs/2025-01-08/01-58-51/Traj-LLM/2yau9l6p/checkpoints/epoch=99-step=4300.ckpt
  output_file: predictions.json

modules:
  sparse_encoder:
    input_dim: 128
    hidden_dim: 256
    output_dim: 128

  high_level_model:
    llm_model_name: meta-llama/Llama-3.2-3B
    input_dim: 128
    hidden_dim: 256
    output_dim: 128

  lane_probability:
    agent_dim: 128
    lane_dim: 128
    hidden_dim: 256
    num_lanes: 10

  laplace_decoder:
    input_dim: 128
    output_dim: 64

  mamba:
    input_dim: 128
    hidden_dim: 256
    num_blocks: 3

data:
  nuscenes_path: /home/user/data/Nuscenes
  train_split: train
  val_split: val
  test_split: test

wandb:
  project: Traj-LLM
  entity: your_wandb_entity  # Replace with your W&B entity name
  mode: online  # online/offline
